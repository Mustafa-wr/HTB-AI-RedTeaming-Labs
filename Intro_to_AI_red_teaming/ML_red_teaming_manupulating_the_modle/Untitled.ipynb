{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7c0f76-c872-42a6-b938-c24e057f238f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 46.6%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Data Helper\n",
    "\n",
    "def preprocess_message(message):\n",
    "    stop_words = set(stopwords.words(\"english\")) - {\"free\", \"win\", \"cash\", \"urgent\"}\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    message = message.lower()\n",
    "    message = re.sub(r\"[^a-z\\s$!]\", \"\", message)\n",
    "    tokens = word_tokenize(message)\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    df['message'] = df['message'].apply(preprocess_message)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Model Helper\n",
    "\n",
    "# classify messages by a trained model\n",
    "def classify_messages(model, msg_df, return_probabilities=False):\n",
    "    if isinstance(msg_df, str):\n",
    "        msg_preprocessed = [preprocess_message(msg_df)]\n",
    "    else:\n",
    "        msg_preprocessed = [preprocess_message(msg) for msg in msg_df]\n",
    "\n",
    "    msg_vectorized = model.named_steps[\"vectorizer\"].transform(msg_preprocessed)\n",
    "\n",
    "    if return_probabilities:\n",
    "        return model.named_steps[\"classifier\"].predict_proba(msg_vectorized)\n",
    "\n",
    "    return model.named_steps[\"classifier\"].predict(msg_vectorized)\n",
    "\n",
    "\n",
    "# train a model on the given data set\n",
    "def train(dataset):\n",
    "    # read training data set\n",
    "    df = pd.read_csv(dataset)\n",
    "\n",
    "    # data preprocessing\n",
    "    df = preprocess_dataframe(df)\n",
    "\n",
    "    # data preparation\n",
    "    vectorizer = CountVectorizer(min_df=1, max_df=0.9, ngram_range=(1, 2))\n",
    "    X = vectorizer.fit_transform(df[\"message\"])\n",
    "    y = df[\"label\"].apply(lambda x: 1 if x == \"spam\" else 0)\n",
    "\n",
    "    # training\n",
    "    pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"classifier\", MultinomialNB())])\n",
    "    param_grid = {\"classifier__alpha\": [0.1, 0.5, 1.0]}\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=\"f1\")\n",
    "    grid_search.fit(df[\"message\"], y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "# evaluate a given model on our test dataset\n",
    "def evaluate(model, dataset):\n",
    "    # read test data set\n",
    "    df = pd.read_csv(dataset)\n",
    "\n",
    "    # prepare labels\n",
    "    df['label'] = df['label'].apply(lambda x: 1 if x == \"spam\" else 0)\n",
    "\n",
    "    # get predictions\n",
    "    predictions = classify_messages(model, df['message'])\n",
    "\n",
    "    # compute accuracy\n",
    "    correct = np.count_nonzero(predictions == df['label'])\n",
    "    return (correct / len(df))\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Main\n",
    "\n",
    "model = train(\"./poison.csv\")\n",
    "acc = evaluate(model, \"./test.csv\")\n",
    "print(f\"Model accuracy: {round(acc*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d81b3252-bbf2-48be-98c0-e1096b468bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Ham\n",
      "Probabilities:\n",
      "\t Ham: 100.0%\n",
      "\tSpam: 0.0%\n"
     ]
    }
   ],
   "source": [
    "message = \"Not yet. Just i'd like to keep in touch and it will be the easiest way to do that from barcelona. By the way how ru and how is the house?\"\n",
    "\n",
    "predicted_class = classify_messages(model, message)[0]\n",
    "predicted_class_str = \"Ham\" if predicted_class == 0 else \"Spam\"\n",
    "probabilities = classify_messages(model, message, return_probabilities=True)[0]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_str}\")\n",
    "print(\"Probabilities:\")\n",
    "print(f\"\\t Ham: {round(probabilities[0]*100, 2)}%\")\n",
    "print(f\"\\tSpam: {round(probabilities[1]*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35052628-80cd-402a-ad52-5e48f0292e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
